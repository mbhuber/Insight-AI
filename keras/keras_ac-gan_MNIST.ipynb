{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "file: mnist_acgan.py\n",
    "author: Luke de Oliveira (lukedeo@vaitech.io)\n",
    "\n",
    "Train an Auxiliary Classifier Generative Adversarial Network (ACGAN) on the\n",
    "MNIST dataset. See https://arxiv.org/abs/1610.09585 for more details.\n",
    "\n",
    "You should start to see reasonable images after ~5 epochs, and good images\n",
    "by ~15 epochs. You should use a GPU, as the convolution-heavy operations are\n",
    "very slow on the CPU. Prefer the TensorFlow backend if you plan on iterating, as\n",
    "the compilation time can be a blocker using Theano.\n",
    "\n",
    "Timings:\n",
    "\n",
    "Hardware           | Backend | Time / Epoch\n",
    "-------------------------------------------\n",
    " CPU               | TF      | 3 hrs\n",
    " Titan X (maxwell) | TF      | 4 min\n",
    " Titan X (maxwell) | TH      | 7 min\n",
    "\n",
    "Consult https://github.com/lukedeo/keras-acgan for more information and\n",
    "example output\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import defaultdict\n",
    "import cPickle as pickle\n",
    "#import cPickle as Pickle\n",
    "\n",
    "from PIL import Image\n",
    "#from Pillow import Image\n",
    "\n",
    "from six.moves import range\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Embedding, merge, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Convolution2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.generic_utils import Progbar\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator(latent_size):\n",
    "    # we will map a pair of (z, L), where z is a latent vector and L is a\n",
    "    # label drawn from P_c, to image space (..., 1, 28, 28)\n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(Dense(1024, input_dim=latent_size, activation='relu'))\n",
    "    cnn.add(Dense(128 * 7 * 7, activation='relu'))\n",
    "    cnn.add(Reshape((128, 7, 7)))\n",
    "\n",
    "    # upsample to (..., 14, 14)\n",
    "    cnn.add(UpSampling2D(size=(2, 2)))\n",
    "    cnn.add(Convolution2D(256, 5, 5, border_mode='same',\n",
    "                          activation='relu', init='glorot_normal'))\n",
    "\n",
    "    # upsample to (..., 28, 28)\n",
    "    cnn.add(UpSampling2D(size=(2, 2)))\n",
    "    cnn.add(Convolution2D(128, 5, 5, border_mode='same',\n",
    "                          activation='relu', init='glorot_normal'))\n",
    "\n",
    "    # take a channel axis reduction\n",
    "    cnn.add(Convolution2D(1, 2, 2, border_mode='same',\n",
    "                          activation='tanh', init='glorot_normal'))\n",
    "\n",
    "    # this is the z space commonly refered to in GAN papers\n",
    "    latent = Input(shape=(latent_size, ))\n",
    "\n",
    "    # this will be our label\n",
    "    image_class = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "    # 10 classes in MNIST\n",
    "    cls = Flatten()(Embedding(10, latent_size,\n",
    "                              init='glorot_normal')(image_class))\n",
    "\n",
    "    # hadamard product between z-space and a class conditional embedding\n",
    "    h = merge([latent, cls], mode='mul')\n",
    "\n",
    "    fake_image = cnn(h)\n",
    "\n",
    "    return Model(input=[latent, image_class], output=fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    # build a relatively standard conv net, with LeakyReLUs as suggested in\n",
    "    # the reference paper\n",
    "    cnn = Sequential()\n",
    "\n",
    "    cnn.add(Convolution2D(32, 3, 3, border_mode='same', subsample=(2, 2),\n",
    "                          input_shape=(1, 28, 28)))\n",
    "    cnn.add(LeakyReLU())\n",
    "    cnn.add(Dropout(0.3))\n",
    "\n",
    "    cnn.add(Convolution2D(64, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "    cnn.add(LeakyReLU())\n",
    "    cnn.add(Dropout(0.3))\n",
    "\n",
    "    cnn.add(Convolution2D(128, 3, 3, border_mode='same', subsample=(2, 2)))\n",
    "    cnn.add(LeakyReLU())\n",
    "    cnn.add(Dropout(0.3))\n",
    "\n",
    "    cnn.add(Convolution2D(256, 3, 3, border_mode='same', subsample=(1, 1)))\n",
    "    cnn.add(LeakyReLU())\n",
    "    cnn.add(Dropout(0.3))\n",
    "\n",
    "    cnn.add(Flatten())\n",
    "\n",
    "    image = Input(shape=(1, 28, 28))\n",
    "\n",
    "    features = cnn(image)\n",
    "\n",
    "    # first output (name=generation) is whether or not the discriminator\n",
    "    # thinks the image that is being shown is fake, and the second output\n",
    "    # (name=auxiliary) is the class that the discriminator thinks the image\n",
    "    # belongs to.\n",
    "    fake = Dense(1, activation='sigmoid', name='generation')(features)\n",
    "    aux = Dense(10, activation='softmax', name='auxiliary')(features)\n",
    "\n",
    "    return Model(input=image, output=[fake, aux])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch and latent size taken from the paper\n",
    "nb_epochs = 1#50\n",
    "batch_size = 32#100\n",
    "latent_size = 100\n",
    "\n",
    "# Adam parameters suggested in https://arxiv.org/abs/1511.06434\n",
    "adam_lr = 0.0002\n",
    "adam_beta_1 = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(\n",
    "    optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "    loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    ")\n",
    "\n",
    "# build the generator\n",
    "generator = build_generator(latent_size)\n",
    "generator.compile(optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "                  loss='binary_crossentropy')\n",
    "\n",
    "latent = Input(shape=(latent_size, ))\n",
    "image_class = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "# get a fake image\n",
    "fake = generator([latent, image_class])\n",
    "\n",
    "# we only want to be able to train generation for the combined model\n",
    "discriminator.trainable = False\n",
    "fake, aux = discriminator(fake)\n",
    "combined = Model(input=[latent, image_class], output=[fake, aux])\n",
    "\n",
    "combined.compile(\n",
    "    optimizer=Adam(lr=adam_lr, beta_1=adam_beta_1),\n",
    "    loss=['binary_crossentropy', 'sparse_categorical_crossentropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1000, 1, 28, 28), (1000,)]\n",
      "[(100, 1, 28, 28), (100,)]\n"
     ]
    }
   ],
   "source": [
    "# get our mnist data, and force it to be of shape (..., 1, 28, 28) with\n",
    "# range [-1, 1]\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "X_train = np.expand_dims(X_train, axis=1)\n",
    "\n",
    "# reduce training set for testing\n",
    "ntrain=1000\n",
    "X_train, y_train = X_train[:ntrain], y_train[:ntrain]\n",
    "\n",
    "print([X_train.shape,y_train.shape])\n",
    "\n",
    "\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# reduce test set for testing\n",
    "ntest=100\n",
    "X_test, y_test = X_test[:ntest], y_train[:ntest]\n",
    "\n",
    "print([X_test.shape,y_test.shape])\n",
    "\n",
    "nb_train, nb_test = X_train.shape[0], X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100)\n",
      "32/32 [==============================] - 1s\n"
     ]
    }
   ],
   "source": [
    "noise = np.random.uniform(-1, 1, (batch_size, 100))\n",
    "print(noise.shape)\n",
    "generated_images = generator.predict(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampled_labels = np.random.randint(0, 10, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 1\n",
      " 1/31 [..............................] - ETA: 224s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-91-ce9d78e6e3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         epoch_gen_loss.append(combined.train_on_batch(\n\u001b[0;32m---> 52\u001b[0;31m             [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTesting for epoch {}:'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/envs/tf_py2.7/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)\n",
    "\n",
    "ct = time.time()\n",
    "for epoch in range(nb_epochs):\n",
    "    print('Epoch {} of {}'.format(epoch + 1, nb_epochs))\n",
    "\n",
    "    nb_batches = int(X_train.shape[0] / batch_size)\n",
    "    progress_bar = Progbar(target=nb_batches)\n",
    "\n",
    "    epoch_gen_loss = []\n",
    "    epoch_disc_loss = []\n",
    "\n",
    "    for index in range(nb_batches):\n",
    "        progress_bar.update(index)\n",
    "        # generate a new batch of noise\n",
    "        noise = np.random.uniform(-1, 1, (batch_size, latent_size))\n",
    "\n",
    "        # get a batch of real images\n",
    "        image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "        label_batch = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "        # sample some labels from p_c\n",
    "        sampled_labels = np.random.randint(0, 10, batch_size)\n",
    "\n",
    "        # generate a batch of fake images, using the generated labels as a\n",
    "        # conditioner. We reshape the sampled labels to be\n",
    "        # (batch_size, 1) so that we can feed them into the embedding\n",
    "        # layer as a length one sequence\n",
    "        generated_images = generator.predict(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], verbose=0)\n",
    "\n",
    "        X = np.concatenate((image_batch, generated_images))\n",
    "        y = np.array([1] * batch_size + [0] * batch_size)\n",
    "        aux_y = np.concatenate((label_batch, sampled_labels), axis=0)\n",
    "\n",
    "        # see if the discriminator can figure itself out...\n",
    "        epoch_disc_loss.append(discriminator.train_on_batch(X, [y, aux_y]))\n",
    "\n",
    "        # make new noise. we generate 2 * batch size here such that we have\n",
    "        # the generator optimize over an identical number of images as the\n",
    "        # discriminator\n",
    "        noise = np.random.uniform(-1, 1, (2 * batch_size, latent_size))\n",
    "        sampled_labels = np.random.randint(0, 10, 2 * batch_size)\n",
    "\n",
    "        # we want to train the genrator to trick the discriminator\n",
    "        # For the generator, we want all the {fake, not-fake} labels to say\n",
    "        # not-fake\n",
    "        trick = np.ones(2 * batch_size)\n",
    "\n",
    "        epoch_gen_loss.append(combined.train_on_batch(\n",
    "            [noise, sampled_labels.reshape((-1, 1))], [trick, sampled_labels]))\n",
    "\n",
    "    print('\\nTesting for epoch {}:'.format(epoch + 1))\n",
    "\n",
    "    # evaluate the testing loss here\n",
    "\n",
    "    # generate a new batch of noise\n",
    "    noise = np.random.uniform(-1, 1, (nb_test, latent_size))\n",
    "\n",
    "    # sample some labels from p_c and generate images from them\n",
    "    sampled_labels = np.random.randint(0, 10, nb_test)\n",
    "    generated_images = generator.predict(\n",
    "        [noise, sampled_labels.reshape((-1, 1))], verbose=False)\n",
    "\n",
    "    X = np.concatenate((X_test, generated_images))\n",
    "    y = np.array([1] * nb_test + [0] * nb_test)\n",
    "    aux_y = np.concatenate((y_test, sampled_labels), axis=0)\n",
    "\n",
    "    # see if the discriminator can figure itself out...\n",
    "    discriminator_test_loss = discriminator.evaluate(\n",
    "        X, [y, aux_y], verbose=False)\n",
    "\n",
    "    discriminator_train_loss = np.mean(np.array(epoch_disc_loss), axis=0)\n",
    "\n",
    "    # make new noise\n",
    "    noise = np.random.uniform(-1, 1, (2 * nb_test, latent_size))\n",
    "    sampled_labels = np.random.randint(0, 10, 2 * nb_test)\n",
    "\n",
    "    trick = np.ones(2 * nb_test)\n",
    "\n",
    "    generator_test_loss = combined.evaluate(\n",
    "        [noise, sampled_labels.reshape((-1, 1))],\n",
    "        [trick, sampled_labels], verbose=False)\n",
    "\n",
    "    generator_train_loss = np.mean(np.array(epoch_gen_loss), axis=0)\n",
    "\n",
    "    # generate an epoch report on performance\n",
    "    train_history['generator'].append(generator_train_loss)\n",
    "    train_history['discriminator'].append(discriminator_train_loss)\n",
    "\n",
    "    test_history['generator'].append(generator_test_loss)\n",
    "    test_history['discriminator'].append(discriminator_test_loss)\n",
    "\n",
    "    print('{0:<22s} | {1:4s} | {2:15s} | {3:5s}'.format(\n",
    "        'component', *discriminator.metrics_names))\n",
    "    print('-' * 65)\n",
    "\n",
    "    ROW_FMT = '{0:<22s} | {1:<4.2f} | {2:<15.2f} | {3:<5.2f}'\n",
    "    print(ROW_FMT.format('generator (train)',\n",
    "                         *train_history['generator'][-1]))\n",
    "    print(ROW_FMT.format('generator (test)',\n",
    "                         *test_history['generator'][-1]))\n",
    "    print(ROW_FMT.format('discriminator (train)',\n",
    "                         *train_history['discriminator'][-1]))\n",
    "    print(ROW_FMT.format('discriminator (test)',\n",
    "                         *test_history['discriminator'][-1]))\n",
    "\n",
    "    # save weights every epoch\n",
    "    generator.save_weights(\n",
    "        'params_generator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "    discriminator.save_weights(\n",
    "        'params_discriminator_epoch_{0:03d}.hdf5'.format(epoch), True)\n",
    "\n",
    "    # generate some digits to display\n",
    "    noise = np.random.uniform(-1, 1, (100, latent_size))\n",
    "\n",
    "    sampled_labels = np.array([\n",
    "        [i] * 10 for i in range(10)\n",
    "    ]).reshape(-1, 1)\n",
    "\n",
    "    # get a batch to display\n",
    "    generated_images = generator.predict(\n",
    "        [noise, sampled_labels], verbose=0)\n",
    "\n",
    "    # arrange them into a grid\n",
    "    img = (np.concatenate([r.reshape(-1, 28)\n",
    "                           for r in np.split(generated_images, 10)\n",
    "                           ], axis=-1) * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "    Image.fromarray(img).save(\n",
    "        'plot_epoch_{0:03d}_generated.png'.format(epoch))\n",
    "\n",
    "pickle.dump({'train': train_history, 'test': test_history},\n",
    "            open('acgan-history.pkl', 'wb'))\n",
    "\n",
    "print(\"Elapsed time= {} min\".format((time.time()-ct)/60.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_8 (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 100)        1000        input_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "input_7 (InputLayer)             (None, 100)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)              (None, 100)           0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 100)           0           input_7[0][0]                    \n",
      "                                                                   flatten_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)        (None, 1, 28, 28)     8171521     merge_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 8,172,521\n",
      "Trainable params: 8,172,521\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 100)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.layers[5].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
